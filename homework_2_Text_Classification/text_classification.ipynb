{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `521H0489 - Hồ Hữu An`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Text Classificaiton`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from underthesea import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31460, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Áo bao đẹp ạ!</td>\n",
       "      <td>POS</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuyệt vời</td>\n",
       "      <td>POS</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2day ao khong giong trong</td>\n",
       "      <td>NEG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mùi thơm,bôi lên da mềm da</td>\n",
       "      <td>POS</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vải đẹp, dày dặn</td>\n",
       "      <td>POS</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      content label  start\n",
       "0               Áo bao đẹp ạ!   POS      5\n",
       "1                   Tuyệt vời   POS      5\n",
       "2   2day ao khong giong trong   NEG      1\n",
       "3  Mùi thơm,bôi lên da mềm da   POS      5\n",
       "4            Vải đẹp, dày dặn   POS      5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'sentimentVN.csv'\n",
    "df = pd.read_csv(filename)\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install underthesea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Áo bao đẹp ạ!\tPOS\n",
      "Tuyệt vời\tPOS\n",
      "2day ao khong giong trong\tNEG\n",
      "Mùi thơm,bôi lên da mềm da\tPOS\n",
      "Vải đẹp, dày dặn\tPOS\n"
     ]
    }
   ],
   "source": [
    "max = 10000\n",
    "X = df['content'][:max].astype(str)\n",
    "y = df['label'][:max]\n",
    "for i in range(5):\n",
    "    print(X[i],end='\\t')\n",
    "    print(y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "áo bao đẹp ạ !\n",
      "tuyệt_vời\n",
      "2 day ao khong_giong trong\n",
      "mùi thơm , bôi lên da mềm da\n",
      "vải đẹp , dày dặn\n",
      "hàng rất đẹp , rất chi là ưng_ý\n",
      "chất_lượng sản_phẩm tốt , date dài\n",
      "ăn_nói và thái_độ phục_vụ tốt\n",
      "đóng_gói sản_phẩm chắc_chắn\n",
      "tất_sờn hết ca chưa dùng mà vay r\n"
     ]
    }
   ],
   "source": [
    "Xnew = [word_tokenize(sent,format='text').lower() for sent in X]\n",
    "for i in range(10):\n",
    "    print(Xnew[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chàng', 'N'),\n",
       " ('trai', 'N'),\n",
       " ('ấy', 'P'),\n",
       " ('thích', 'V'),\n",
       " ('cô', 'Nc'),\n",
       " ('gái', 'N'),\n",
       " ('không', 'R'),\n",
       " ('xinh', 'A'),\n",
       " ('trong', 'E'),\n",
       " ('lớp_học', 'M')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from underthesea import pos_tag\n",
    "sent = 'chàng trai ấy thích cô gái không xinh trong lớp học'\n",
    "ws = word_tokenize(sent,format='text')\n",
    "pos_tag(ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: Keras-Preprocessing in c:\\users\\an\\appdata\\roaming\\python\\python311\\site-packages (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\an\\appdata\\roaming\\python\\python311\\site-packages (from Keras-Preprocessing) (1.23.5)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\an\\appdata\\roaming\\python\\python311\\site-packages (from Keras-Preprocessing) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\programdata\\anaconda3\\lib\\site-packages\\vboxapi-1.0-py3.11.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: C:\\ProgramData\\anaconda3\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install Keras-Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts(Xnew)\n",
    "#print(t.word_index)\n",
    "#print(t.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3579)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X = t.texts_to_matrix(Xnew, mode='count')\n",
    "print(X.shape)\n",
    "print(X[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500, 3579)\n",
      "(7500,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42,\n",
    "                                                    test_size=0.25)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Training`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Naive Bayes`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.60      0.67      0.64       483\n",
      "         NEU       0.38      0.38      0.38       415\n",
      "         POS       0.87      0.84      0.85      1602\n",
      "\n",
      "    accuracy                           0.73      2500\n",
      "   macro avg       0.62      0.63      0.62      2500\n",
      "weighted avg       0.74      0.73      0.73      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train,y_train)\n",
    "y_pred = nb_model.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Logistic Regression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.67      0.66      0.66       483\n",
      "         NEU       0.38      0.29      0.33       415\n",
      "         POS       0.85      0.90      0.88      1602\n",
      "\n",
      "    accuracy                           0.76      2500\n",
      "   macro avg       0.63      0.62      0.62      2500\n",
      "weighted avg       0.74      0.76      0.74      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression(random_state=42)\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "print(\"Logistic Regression Results:\")\n",
    "print(classification_report(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Support Vector Machine`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine Results:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.68      0.69      0.68       483\n",
      "         NEU       0.43      0.26      0.32       415\n",
      "         POS       0.84      0.93      0.88      1602\n",
      "\n",
      "    accuracy                           0.77      2500\n",
      "   macro avg       0.65      0.62      0.63      2500\n",
      "weighted avg       0.74      0.77      0.75      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_pred = svm_model.predict(X_test)\n",
    "print(\"Support Vector Machine Results:\")\n",
    "print(classification_report(y_test, svm_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Save models`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'naive_bayes': nb_model,\n",
    "    'logistic_regression': lr_model,\n",
    "    'svm': svm_model\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    with open(f'{name}_model.pkl', 'wb') as file:\n",
    "        pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tôi thích nó\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n",
      "['NEU']\n"
     ]
    }
   ],
   "source": [
    "question = input()\n",
    "print(question)\n",
    "X_input = t.texts_to_matrix([question],mode='count')\n",
    "print(X_input)\n",
    "y_output = model.predict(X_input)\n",
    "print(y_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a model for prediction:\n",
      "1. Naive Bayes\n",
      "2. Logistic Regression\n",
      "3. Support Vector Machine\n",
      "4. Exit\n",
      "\n",
      "Question: thằng chó\n",
      "\n",
      "Predicted sentiment: NEG\n",
      "\n",
      "Select a model for prediction:\n",
      "1. Naive Bayes\n",
      "2. Logistic Regression\n",
      "3. Support Vector Machine\n",
      "4. Exit\n",
      "End.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "def load_model(model_name):\n",
    "    with open(f'{model_name}_model.pkl', 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "def predict_sentiment(question, model_name):\n",
    "    model = load_model(model_name)\n",
    "    X_input = t.texts_to_matrix([question], mode='count')\n",
    "    y_output = model.predict(X_input)\n",
    "    return y_output[0]\n",
    "\n",
    "while True:\n",
    "    print(\"Select a model for prediction:\")\n",
    "    print(\"1. Naive Bayes\")\n",
    "    print(\"2. Logistic Regression\")\n",
    "    print(\"3. Support Vector Machine\")\n",
    "    print(\"4. Exit\")\n",
    "    \n",
    "    choice = input(\"Enter your choice (1-4): \")\n",
    "    \n",
    "    if choice == '4':\n",
    "        print(\"End.\")\n",
    "        break\n",
    "    \n",
    "    if choice not in ['1', '2', '3', '4']:\n",
    "        print(\"Invalid choice. Please try again.\")\n",
    "        continue\n",
    "    \n",
    "    model_names = ['naive_bayes', 'logistic_regression', 'svm']\n",
    "    selected_model = model_names[int(choice) - 1]\n",
    "    \n",
    "    question = input(\"Enter the text for sentiment analysis: \")\n",
    "    result = predict_sentiment(question, selected_model)\n",
    "    print(f\"\\nQuestion: {question}\\n\")\n",
    "    print(f\"Predicted sentiment: {result}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
