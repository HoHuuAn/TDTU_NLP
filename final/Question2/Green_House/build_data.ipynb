{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kor!\n",
    "from kor.extraction import create_extraction_chain\n",
    "from kor.nodes import Object, Text, Number\n",
    "\n",
    "# LangChain Models\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Standard Helpers\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Text Helpers\n",
    "from bs4 import BeautifulSoup\n",
    "from markdownify import markdownify as md\n",
    "\n",
    "\n",
    "# Project Hepers\n",
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'GOOGLE_API_KEY' not in os.environ:\n",
    "    os.environ['GOOGLE_API_KEY'] = getpass.getpass('Provide your Google API Key: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model='gemini-1.5-flash-002', temperature=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_broad_tokens(file_path=\"Data/board_tokens.txt\"):\n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            return [line.strip() for line in file.readlines()]\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {file_path} not found.\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_from_greenhouse(board_token):\n",
    "    url = f'https://boards-api.greenhouse.io/v1/boards/{board_token}/jobs?content=true'\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "    except:\n",
    "        print (\"Whoops, error\")\n",
    "        return\n",
    "        \n",
    "    status_code = response.status_code\n",
    "    \n",
    "    jobs = response.json()['jobs']\n",
    "    \n",
    "    print (f\"{board_token}: {status_code}, Found {len(jobs)} jobs\")\n",
    "    \n",
    "    return jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = Object(\n",
    "    id=\"job_description\",\n",
    "    description=\"\"\"\n",
    "        A detailed description of a job listing including core responsibilities, required skills, educational requirements, experience level, preferred qualifications, and compensation and benefits.\n",
    "    \"\"\",\n",
    "    attributes=[\n",
    "        Text(\n",
    "            id=\"core_responsibilities\",\n",
    "            description=\"The main duties and tasks associated with the job\"\n",
    "        ),\n",
    "        Text(\n",
    "            id=\"required_skills\",\n",
    "            description=\"The skills that are necessary to perform the job\"\n",
    "        ),\n",
    "        Text(\n",
    "            id=\"educational_requirements\",\n",
    "            description=\"The educational background required for the job\"\n",
    "        ),\n",
    "        Text(\n",
    "            id=\"experience_level\",\n",
    "            description=\"The level of experience required for the job\"\n",
    "        ),\n",
    "        Text(\n",
    "            id=\"preferred_qualifications\",\n",
    "            description=\"Additional qualifications that are preferred but not required\"\n",
    "        ),\n",
    "        Text(\n",
    "            id=\"compensation_and_benefits\",\n",
    "            description=\"The compensation and benefits offered for the job\"\n",
    "        )\n",
    "    ],\n",
    "    examples=[\n",
    "        (\n",
    "            \"Manage a team of software engineers. Required Skills: Proficient in Python and Java. Educational Requirements: Bachelor's degree in Computer Science. Experience Level: 5+ years of experience. Preferred Qualifications: Experience with cloud computing. Compensation and Benefits: Competitive salary and health benefits.\",\n",
    "            [\n",
    "                {\"core_responsibilities\": \"Manage a team of software engineers\"},\n",
    "                {\"required_skills\": \"Proficient in Python and Java\"},\n",
    "                {\"educational_requirements\": \"Bachelor's degree in Computer Science\"},\n",
    "                {\"experience_level\": \"5+ years of experience\"},\n",
    "                {\"preferred_qualifications\": \"Experience with cloud computing\"},\n",
    "                {\"compensation_and_benefits\": \"Competitive salary and health benefits\"}\n",
    "            ]\n",
    "        ),\n",
    "        (\n",
    "            \"Develop and maintain web applications. Required Skills: Knowledge of HTML, CSS, and JavaScript. Educational Requirements: Associate's degree in Information Technology. Experience Level: 2+ years of experience. Preferred Qualifications: Familiarity with React.js. Compensation and Benefits: Annual bonus and retirement plan.\",\n",
    "            [\n",
    "                {\"core_responsibilities\": \"Develop and maintain web applications\"},\n",
    "                {\"required_skills\": \"Knowledge of HTML, CSS, and JavaScript\"},\n",
    "                {\"educational_requirements\": \"Associate's degree in Information Technology\"},\n",
    "                {\"experience_level\": \"2+ years of experience\"},\n",
    "                {\"preferred_qualifications\": \"Familiarity with React.js\"},\n",
    "                {\"compensation_and_benefits\": \"Annual bonus and retirement plan\"}\n",
    "            ]\n",
    "        )\n",
    "    ],\n",
    "    many=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_job_description(job):\n",
    "    soup = BeautifulSoup(job['content'], 'html.parser')\n",
    "    return soup.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_jobs_and_save(tokens, extractor, output_file=\"data.json\"):\n",
    "    all_jobs_data = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        jobs = pull_from_greenhouse(token)\n",
    "        \n",
    "        for job in jobs:\n",
    "            description = process_job_description(job)\n",
    "            text = md(description)\n",
    "\n",
    "            chain = create_extraction_chain(llm, extractor, input_formatter=\"triple_quotes\")\n",
    "            extraction = chain.invoke(input=text)[\"data\"]\n",
    "            \n",
    "            job_data = {\n",
    "                \"description\": description,\n",
    "                \"extraction\": extraction\n",
    "            }\n",
    "            all_jobs_data.append(job_data)\n",
    "    \n",
    "    with open(output_file, \"w\") as json_file:\n",
    "        json.dump(all_jobs_data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = load_broad_tokens(file_path=\"Data/board_tokens.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tokens = len(tokens)\n",
    "split_1 = int(total_tokens * 0.5)\n",
    "split_2 = int(total_tokens * 0.8)\n",
    "\n",
    "tokens_train = tokens[:split_1]\n",
    "tokens_val = tokens[split_1:split_2]\n",
    "tokens_test = tokens[split_2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_jobs_and_save(tokens_train, extractor, output_file=\"Data/train.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_jobs_and_save(tokens_val, extractor, output_file=\"Data/val.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_jobs_and_save(tokens_test, extractor, output_file=\"Data/test.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
