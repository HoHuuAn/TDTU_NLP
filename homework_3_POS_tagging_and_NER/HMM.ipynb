{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tag import hmm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from CSV\n",
    "data = pd.read_csv('ner.csv', encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "sentences = []\n",
    "pos_tags = []\n",
    "ner_tags = []\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    sentence = row['Sentence'].split()\n",
    "    pos = eval(row['POS'])\n",
    "    ner = eval(row['Tag'])\n",
    "    sentences.append(sentence)\n",
    "    pos_tags.append(pos)\n",
    "    ner_tags.append(ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"', 'And', 'I', 'think', 'they', \"'ll\", 'want', 'a', 'one-stop', 'shop', 'in', 'terms', 'of', 'combining', 'security', ',', 'immigration', ',', 'customs', ',', 'and', 'quarantine', 'together', 'Â…', 'just', 'to', 'make', 'sure', 'it', \"'s\", 'more', 'streamlined', 'and', 'provides', 'more', 'certainty', '.', '\"']\n"
     ]
    }
   ],
   "source": [
    "print((sentences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_pos = []\n",
    "training_data_ner = []\n",
    "len\n",
    "for sent, pos, ner in zip(sentences, pos_tags, ner_tags):\n",
    "    if len(sent) != len(pos) or len(sent) != len(ner):\n",
    "        print(sent)\n",
    "        raise ValueError(f\"Mismatch in lengths: words ({len(sent)}), POS tags ({len(pos)}), NER tags ({len(ner)})\\n {sent}\")\n",
    "    \n",
    "    sent_pos = list(zip(sent, pos))\n",
    "    sent_ner = list(zip(sent, ner))\n",
    "    training_data_pos.append(sent_pos)\n",
    "    training_data_ner.append(sent_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "train_pos, test_pos = train_test_split(training_data_pos, test_size=0.2, random_state=42)\n",
    "train_ner, test_ner = train_test_split(training_data_ner, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    def __init__(self):\n",
    "        self.transition_probs = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "        self.emission_probs = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "        self.initial_probs = defaultdict(lambda: 0)\n",
    "        self.states = set()\n",
    "        self.vocabulary = set()\n",
    "    \n",
    "    def train(self, tagged_sentences):\n",
    "        # Count occurrences for transition, emission, and initial probabilities\n",
    "        for sentence in tagged_sentences:\n",
    "            prev_tag = None\n",
    "            for idx, (word, tag) in enumerate(sentence):\n",
    "                self.vocabulary.add(word)\n",
    "                self.states.add(tag)\n",
    "                \n",
    "                if idx == 0:\n",
    "                    self.initial_probs[tag] += 1  # Initial tag\n",
    "                else:\n",
    "                    self.transition_probs[prev_tag][tag] += 1  # Transition from prev tag to current tag\n",
    "                \n",
    "                self.emission_probs[tag][word] += 1  # Emission probability of word given tag\n",
    "                \n",
    "                prev_tag = tag\n",
    "        \n",
    "        # Normalize counts to probabilities\n",
    "        self._normalize_probs()\n",
    "    \n",
    "    def _normalize_probs(self):\n",
    "        # Normalize initial probabilities\n",
    "        total_initials = sum(self.initial_probs.values())\n",
    "        for tag in self.initial_probs:\n",
    "            self.initial_probs[tag] /= total_initials\n",
    "        \n",
    "        # Normalize transition probabilities\n",
    "        for prev_tag in self.transition_probs:\n",
    "            total_transitions = sum(self.transition_probs[prev_tag].values())\n",
    "            for tag in self.transition_probs[prev_tag]:\n",
    "                self.transition_probs[prev_tag][tag] /= total_transitions\n",
    "        \n",
    "        # Normalize emission probabilities\n",
    "        for tag in self.emission_probs:\n",
    "            total_emissions = sum(self.emission_probs[tag].values())\n",
    "            for word in self.emission_probs[tag]:\n",
    "                self.emission_probs[tag][word] /= total_emissions\n",
    "    \n",
    "    def viterbi(self, sentence):\n",
    "        V = [{}] \n",
    "        path = {} \n",
    "        \n",
    "        # Initialization step\n",
    "        for tag in self.states:\n",
    "            V[0][tag] = self.initial_probs[tag] * self.emission_probs[tag].get(sentence[0], 1e-6)\n",
    "            path[tag] = [tag]\n",
    "        \n",
    "        # Recursion step\n",
    "        for t in range(1, len(sentence)):\n",
    "            V.append({})\n",
    "            new_path = {}\n",
    "            \n",
    "            for curr_tag in self.states:\n",
    "                (prob, best_prev_tag) = max(\n",
    "                    (V[t-1][prev_tag] * self.transition_probs[prev_tag].get(curr_tag, 1e-6) * self.emission_probs[curr_tag].get(sentence[t], 1e-6), prev_tag)\n",
    "                    for prev_tag in self.states\n",
    "                )\n",
    "                \n",
    "                V[t][curr_tag] = prob\n",
    "                new_path[curr_tag] = path[best_prev_tag] + [curr_tag]\n",
    "            \n",
    "            path = new_path\n",
    "        \n",
    "        # Termination step: Find the best final tag\n",
    "        n = len(sentence) - 1\n",
    "        (prob, best_tag) = max((V[n][tag], tag) for tag in self.states)\n",
    "        \n",
    "        return path[best_tag], prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(hmm, test_data):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    # Iterate over the test sentences\n",
    "    for sentence in test_data:\n",
    "        words = [word for word, tag in sentence]\n",
    "        true_tags = [tag for word, tag in sentence]\n",
    "        \n",
    "        # Use the HMM to predict tags for the words in the sentence\n",
    "        predicted_tags, _ = hmm.viterbi(words)\n",
    "        \n",
    "        # Append to the overall lists of true and predicted tags\n",
    "        y_true.extend(true_tags)\n",
    "        y_pred.extend(predicted_tags)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sentence: [('In', 'IN'), ('Tehran', 'NNP'), (',', ','), ('the', 'DT'), ('chief', 'NN'), ('of', 'IN'), ('Iran', 'NNP'), (\"'s\", 'POS'), ('Revolutionary', 'NNP'), ('Guards', 'NNPS'), (',', ','), ('General', 'NNP'), ('Yahya', 'NNP'), ('Rahim', 'NNP'), ('Safavi', 'NNP'), (',', ','), ('said', 'VBD'), ('Saturday', 'NNP'), ('his', 'PRP$'), ('country', 'NN'), ('would', 'MD'), ('use', 'VB'), ('ballistic', 'JJ'), ('missiles', 'NNS'), ('to', 'TO'), ('defend', 'VB'), ('itself', 'PRP'), ('if', 'IN'), ('attacked', 'VBN'), ('.', '.')]\n",
      "Predicted Tags: ['DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN', 'DT', 'NN', 'IN']\n",
      "Probability of the sequence: 2.1062239456930328e-194\n"
     ]
    }
   ],
   "source": [
    "hmm_pos = HMM()\n",
    "hmm_pos.train(train_pos)\n",
    "\n",
    "# Predict using Viterbi algorithm\n",
    "predicted_tags, probability = hmm_pos.viterbi(test_pos[0])\n",
    "\n",
    "# Show the result\n",
    "print(\"Test Sentence:\", test_pos[0])\n",
    "print(\"Predicted Tags:\", predicted_tags)\n",
    "print(\"Probability of the sequence:\", probability)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9671\n",
      "Precision: 0.9673\n",
      "Recall: 0.9671\n",
      "F1 Score: 0.9671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9670758848445689,\n",
       " 0.9672677171193271,\n",
       " 0.9670758848445689,\n",
       " 0.9670616423048712)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(hmm_pos, test_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sentence: [('In', 'O'), ('Tehran', 'B-tim'), (',', 'O'), ('the', 'O'), ('chief', 'O'), ('of', 'O'), ('Iran', 'B-geo'), (\"'s\", 'O'), ('Revolutionary', 'B-geo'), ('Guards', 'I-geo'), (',', 'O'), ('General', 'B-org'), ('Yahya', 'I-org'), ('Rahim', 'I-org'), ('Safavi', 'I-org'), (',', 'O'), ('said', 'O'), ('Saturday', 'B-tim'), ('his', 'O'), ('country', 'O'), ('would', 'O'), ('use', 'O'), ('ballistic', 'O'), ('missiles', 'O'), ('to', 'O'), ('defend', 'O'), ('itself', 'O'), ('if', 'O'), ('attacked', 'O'), ('.', 'O')]\n",
      "Predicted Tags: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Probability of the sequence: 2.42520294864314e-182\n"
     ]
    }
   ],
   "source": [
    "hmm_ner = HMM()\n",
    "hmm_ner.train(train_ner)\n",
    "\n",
    "predicted_tags, probability = hmm_ner.viterbi(test_ner[0])\n",
    "\n",
    "print(\"Test Sentence:\", test_ner[0])\n",
    "print(\"Predicted Tags:\", predicted_tags)\n",
    "print(\"Probability of the sequence:\", probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9587\n",
      "Precision: 0.9577\n",
      "Recall: 0.9587\n",
      "F1 Score: 0.9577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9586569985880776,\n",
       " 0.9577115666637515,\n",
       " 0.9586569985880776,\n",
       " 0.9577431568000045)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(hmm_ner, test_ner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using hmm of nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train HMM for POS tagging\n",
    "trainer_pos = hmm.HiddenMarkovModelTrainer()\n",
    "hmm_pos = trainer_pos.train(train_pos)\n",
    "\n",
    "# Train HMM for NER tagging\n",
    "trainer_ner = hmm.HiddenMarkovModelTrainer()\n",
    "hmm_ner = trainer_ner.train(train_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(test_data, hmm_model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for sentence in test_data:\n",
    "        words = [word for word, tag in sentence]\n",
    "        true_tags = [tag for word, tag in sentence]\n",
    "        predicted_tags = hmm_model.tag(words)\n",
    "        predicted_tags = [tag for word, tag in predicted_tags]\n",
    "\n",
    "        for true_tag, pred_tag in zip(true_tags, predicted_tags):\n",
    "            if true_tag == pred_tag:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS Tagging Accuracy: 83.23%\n",
      "NER Tagging Accuracy: 94.47%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate POS tagging\n",
    "pos_accuracy = evaluate_model(test_pos, hmm_pos)\n",
    "print(f\"POS Tagging Accuracy: {pos_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Evaluate NER tagging\n",
    "ner_accuracy = evaluate_model(test_ner, hmm_ner)\n",
    "print(f\"NER Tagging Accuracy: {ner_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [word for word, tag in test_pos[0]]\n",
    "true_tags = [tag for word, tag in test_pos[0]]\n",
    "predicted_tags = hmm_pos.tag(words)\n",
    "predicted_tags = [tag for word, tag in predicted_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['JJ', 'NNS', 'VBN', 'DT', 'JJ', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP', 'NNP']\n",
      "['JJ', 'NNS', 'VBN', 'DT', 'JJ', 'NN', 'IN', 'NNP', 'DT', 'NN', 'IN', 'DT', 'NNP', 'CD', 'NNS', ',', 'WDT', 'VBD', 'DT', 'NNS', 'CC', 'VBD', 'NN', 'TO', 'NNP', 'CD', 'NNS', 'IN', 'NN', 'NNS', 'VBD', 'CD', 'NNS', 'IN', 'DT', 'JJ', 'NN', '.']\n"
     ]
    }
   ],
   "source": [
    "print(predicted_tags)\n",
    "print(true_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using hmmlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ast import literal_eval\n",
    "\n",
    "data = pd.read_csv('test.csv')\n",
    "\n",
    "data['POS'] = data['POS'].apply(literal_eval)\n",
    "data['Tag'] = data['Tag'].apply(literal_eval)\n",
    "\n",
    "def encode_sequences(sequences, token_to_idx):\n",
    "    return [[token_to_idx[token] for token in seq] for seq in sequences]\n",
    "\n",
    "unique_pos_tags = list(set(tag for tags in data['POS'] for tag in tags))\n",
    "unique_ner_tags = list(set(tag for tags in data['Tag'] for tag in tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_to_idx = {tag: i for i, tag in enumerate(unique_pos_tags)}\n",
    "ner_to_idx = {tag: i for i, tag in enumerate(unique_ner_tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_pos = {i: tag for tag, i in pos_to_idx.items()}\n",
    "idx_to_ner = {i: tag for tag, i in ner_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_pos = encode_sequences(data['POS'], pos_to_idx)\n",
    "encoded_ner = encode_sequences(data['Tag'], ner_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos, test_pos = train_test_split(encoded_pos, test_size=0.2, random_state=42)\n",
    "train_ner, test_ner = train_test_split(encoded_ner, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted POS tags: ['PDT', 'VBN', 'VBP', 'WDT', 'NNPS', 'JJR', 'DT', 'PRP$', 'NNP', 'JJR', 'DT', 'PRP$', 'NNP', 'JJR', 'DT', 'PRP$', 'NNP', 'JJR', 'DT', 'PRP$', 'NNP', 'JJR', 'DT', 'PRP$', 'NNP', 'JJR', 'DT', 'PRP$', 'NNP', 'JJR', 'DT', 'PRP$', 'NNP', 'JJR', 'DT', 'PRP$', 'NNP', 'JJR']\n"
     ]
    }
   ],
   "source": [
    "n_components_pos = len(pos_to_idx)\n",
    "\n",
    "pos_hmm = hmm.MultinomialHMM(n_components=n_components_pos, n_iter=100, tol=0.01)\n",
    "\n",
    "train_lengths_pos = [len(seq) for seq in train_pos]\n",
    "train_concat_pos = np.concatenate(train_pos)\n",
    "\n",
    "pos_hmm.fit(train_concat_pos.reshape(-1, 1), lengths=train_lengths_pos)\n",
    "\n",
    "def decode_hmm(model, test_seq):\n",
    "    logprob, hidden_states = model.decode(np.array(test_seq).reshape(-1, 1), algorithm=\"viterbi\")\n",
    "    return hidden_states\n",
    "\n",
    "test_seq_pos = test_pos[0]\n",
    "predicted_states_pos = decode_hmm(pos_hmm, test_seq_pos)\n",
    "decoded_pos_tags = [idx_to_pos[state] for state in predicted_states_pos]\n",
    "print(\"Predicted POS tags:\", decoded_pos_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MultinomialHMM has undergone major changes. The previous version was implementing a CategoricalHMM (a special case of MultinomialHMM). This new implementation follows the standard definition for a Multinomial distribution (e.g. as in https://en.wikipedia.org/wiki/Multinomial_distribution). See these issues for details:\n",
      "https://github.com/hmmlearn/hmmlearn/issues/335\n",
      "https://github.com/hmmlearn/hmmlearn/issues/340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted NER tags: ['I-org', 'B-tim', 'I-org', 'B-tim', 'I-org', 'B-tim', 'I-org', 'B-tim', 'I-org', 'B-tim', 'I-org', 'B-tim', 'I-org', 'B-tim', 'I-org', 'B-tim', 'I-org', 'B-tim', 'I-org', 'B-tim', 'I-org', 'B-tim', 'I-org', 'B-tim', 'I-org', 'B-tim', 'I-org', 'B-tim', 'I-org', 'B-tim', 'I-org', 'B-tim', 'I-org', 'B-tim', 'I-org', 'B-tim', 'I-org', 'B-tim']\n"
     ]
    }
   ],
   "source": [
    "n_components_ner = len(ner_to_idx)\n",
    "\n",
    "ner_hmm = hmm.MultinomialHMM(n_components=n_components_ner, n_iter=100, tol=0.01)\n",
    "\n",
    "train_lengths_ner = [len(seq) for seq in train_ner]\n",
    "train_concat_ner = np.concatenate(train_ner)\n",
    "\n",
    "ner_hmm.fit(train_concat_ner.reshape(-1, 1), lengths=train_lengths_ner)\n",
    "\n",
    "test_seq_ner = test_ner[0]\n",
    "predicted_states_ner = decode_hmm(ner_hmm, test_seq_ner)\n",
    "decoded_ner_tags = [idx_to_ner[state] for state in predicted_states_ner]\n",
    "print(\"Predicted NER tags:\", decoded_ner_tags)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
